# RAG Bookâ€‘QA System â€“ Project Documentation

> **Goal:** Build and ship a Retrievalâ€‘Augmented Generation (RAG) web app that lets a user ask questions about any PDF book and see both an answer _and_ the supporting passages, all before **21â€¯Juneâ€¯2025**.

---

## 1. Highâ€‘Level Architecture

```text
PDF â†’Â Text ChunkerÂ â†’Â OpenAI EmbeddingsÂ â†’Â Qdrant Vector DB
                                     â†˜                â†˜
                           LangChain Retriever â† Streamlit UI â†Â User Question
                                       â†˜
                         GPTâ€‘4oâ€‘mini (via LangChain) â†’Â AnswerÂ +Â Source Chunks
```

* **Chunking**: `RecursiveCharacterTextSplitter` from LangChain slices the book into ~1â€¯kâ€‘token windows with ~200â€‘token overlap.  
* **Embedding**: `textâ€‘embeddingâ€‘3-small` (OpenAI) converts chunks to 1536â€‘dim vectors.  
* **Storage**: Vectors & metadata are stored in **Qdrant** (local `dockerâ€‘compose` or Hamravesh managed instance).  
* **Retrieval**: `qdrant.as_retriever()` returns topâ€‘k chunks.  
* **Generation**: `GPTâ€‘4oâ€‘mini` (6â€‘38â€¯k context) creates concise answers with citations.  
* **UI**: A lightweight **Streamlit** frontâ€‘end.

---

## 2. Tech Stack

| Layer | Tool | Why |
|-------|------|-----|
| Vector DB | **Qdrant 1.9+** | Scalable, hybrid search, easy Docker |  
| NLP / Orchestration | **LangChain 0.2+** | Outâ€‘ofâ€‘theâ€‘box chunking, retrievers, agents |  
| Embeddings | **OpenAI `textâ€‘embeddingâ€‘3-small`** | Fast & cheap (14k tokens/s) |
| LLM | **GPTâ€‘4oâ€‘mini** | 4â€‘series reasoning, 128k context |  
| PDF | **PyPDF** | Robust parsing incl. bookmarks/figures |  
| UI | **Streamlit 1.35** | 1â€‘file prototype -> PaaS ready |  
| DevOps | **DockerÂ + hamravesh.com** | Easy container deploy in IR cloud |  

---

## 3. Milestones & Deliverables

| Phase | Scope | Deliverables | Deadline |
|-------|-------|--------------|----------|
| **1. Ingestion** | Parse, chunk, embed **entire book**, push to Qdrant | *`ingest.py`*, Qdrant collection snapshot, **PNG screenshot** of Qdrant UI heatâ€‘map | **16â€¯Junâ€¯2025** |
| **2. RAG Core** | Build Retrieverâ€‘Generator pipeline, Streamlit UX | *`app.py`*, github repo link, **â‰¤â€¯60â€¯s demo.mp4** | **19â€¯Junâ€¯2025** |
| **3. Shipping** | Dockerize, deploy on **Hamravesh**, social sharing | Public URL, LinkedIn post URL, deploy docs | **21â€¯Junâ€¯2025** |

---

## 4. Repository Layout

```text
rag-book-qa/
â”œâ”€ docker/
â”‚  â”œâ”€ Dockerfile
â”‚  â””â”€ docker-compose.yml
â”œâ”€ notebooks/          # playground & EDA
â”œâ”€ src/
â”‚  â”œâ”€ ingest.py        # Phaseâ€‘1 pipeline
â”‚  â”œâ”€ rag_chain.py     # LangChain wrapper
â”‚  â””â”€ ui_streamlit.py  # Phaseâ€‘2 app
â”œâ”€ tests/
â”œâ”€ .env.example
â””â”€ README.md           # quickâ€‘start
```

---

## 5. Streamlit UX

* ğŸ’¬ **Ask question** â†’ answer appears with **expander** listing top chunks.  
* ğŸ–¼ï¸â€¯Phaseâ€¯1 provides a Qdrant collection **t-SNE plot** PNG on sidebar.

---

## 6. Deployment Notes (Hamravesh)

1. Set environment vars (`OPENAI_API_KEY`, `QDRANT_URL`, etc.).  
2. `docker build -t rag-book-qa:latest . && docker push registry.hamravesh.com/<user>/rag-book-qa`  
3. Configure port `8501`.  



